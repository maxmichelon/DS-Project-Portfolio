Task 3: Write Report

1. The dataset I chose to look into is the Lifestyle_and_Wellbeing_Data found on Kaggle. The dataset contains just under 16,000 survey responses with 24 different features. Some of these features include: Daily stress, weekly mediation, core circle, sleep hours, age, gender and a work life balance score. Here is the link: https://www.kaggle.com/datasets/ydalat/lifestyle-and-wellbeing-data

2. I mixed it up and chose to try and accomplish different tasks with different techniques. For instance, I wanted to see if I could predict the gender of the survery samples using Logistic Regression and Vector support machine machine learning techniques. I chose to try and predict the age groups (there were 4) that a person might belong too based off the other features usign decision trees and random forest machine learning techniques. And lastly I wanted to see how accurately I could predict someones work life balance score using a neural network. 

3. For the preprocessing I dropped the Timestamp column, filled the single na value in the dataset with the median for that column, used onehotencoder for the two categorical variables, scaled all of the numerical columns, and then made a clean: general dataset, training dataset, validation dataset, and test dataset as csv files for the proj3_machine_learning file. 

4. For the first two machine learning techniques in project three the accuracies were very similiar with logistic classifications accuracy being about .65 and the support vector machine having an accuracy of about .66 for both validation and test cases while the training cases were higher. The Random forest was more accurate than the decison tree machine learning method in predicting what age group an individual belonged too with DT accuracy being:  .99 training, .38 validation, and .38 testing and RF: .99 training, .48 validation, and .482 testing. Lastly the nuerual network I made to try and predict an individuals work life balance score had an average of 0.025 training, 0.030 validation, and 0.031 testing for the MSE values.

5. The results across different machine learning techniques varied significantly, this shows the importance of model selection and tuning in predictive accuracy. The overfitting observed in the Decision Trees and Random Forest models, as evidenced by the perfect training accuracy contrasted with lower validation and testing accuracies, suggests that these models might be too complex for our data. In contrast, Logistic Regression and SVM displayed more stable performances across different datasets, indicating a better generalization capability. The Neural Network's MSE values are modest and show slight overfitting, but they are more consistent across training and validation sets compared to extreme overfitting seen in Decision Trees and Random Forests. The results definitely expose some flaws and possible improvements that could be made.